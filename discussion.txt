2.3 Experiments and discussion.

(1). How might you improve the classification accuracy of the Gaussian mixtures,
without adding more training data?

For improving the classification accuracy of the Gaussian mixtures,we can do followings:
(a) Increasing the value of max_iter, we gain the better classification accuracy of Gaussian mixtures .
(b) Increasing component count in order to increase the accurcy.

(2). When would your classifier decide that a given test utterance comes from
none of the trained speaker models, and how would your classifier come to this decision?

 Set up a value named'thereshold', check for convergence so that my classifier can
decide that a given test utterance comes from none of the trained speaker models
by checking the value of loglik_thereshould. If L-prev_L is less than the value
of 'thereshould', return break.



(3). Can you think of some alternative methods for doing speaker identification
 that dont use Gaussian mixtures?

Yes,  Support Vector Machines ?SVM?classifier and K-means can do speaker ideneidfication
that dont use Gaussian mixtures.

3.1 Proportion of correctly identified phonemes
-----------------------------------------------

Using a the default HMM with 8 gaussian mixtures, 3 states, all 30 examples of
training data, all 14 dimensions of the data, and a maximum iteration limit of
20, the number of correctly identified phonemes was found to be 492/1096 or 44.89%.

3.2 Analysis of various HMMs
----------------------------

train size       mixtures        states      max_iter        dimensions      correct/total

    30              8               3           20              14              492/1096
    30              5               3           20              14
    30              2               3           20              14
    30              1               3           20              14

    30              8               3           3               14              503/1096
    24              8               3           3               14              451/1096
    16              8               3           3               14              362/1096
    8               8               3           3               14              196/1096

    30              8               3           20              10              483/1096
    30              8               3           20              7               402/1096
    30              8               3           20              3               260/1096
    30              8               3           20              1               116/1096

    30              8               3           5               14              511/1096
    30              8               3           3               14              506/1096
    30              8               2           5               14              485/1096
    30              8               1           5               14              488/1096

- How might you improve the classification accuracy of the Gaussian mixtures,
without adding more training data?

From the above experiment it is apparent that increasing the number mixtures,
increasing the number of states per mixture, or using a greater number of
dimensions from the training data can all improve classification accuracy.
Going from 3 data dimension (23.7% accuracy) to 10 (44% accuracy) resulted in a
20.3% improvement in classification, which was greatest at 14 dimensions (44.8% accuracy).
At 1 state per mixtures, accuracy was 44.5%, and at 3 states it was 46.1%

Of course, increases in the amount of training data used lead to the most
significant increases in accuracy, from 17.8% at 8 training examples to 45.8%
when using all 30 examples. Interestingly, it appears that restricting the max
number of iteration to 3 lead to a marginally better classification rate than
when the max_iter value was 20 - there was an approximately 1% improvement
in classification rates because of this.


- When would your classifier decide that a given test utterance comes from none
of the trained speaker models, and how would your classifier come to this decision?

The classifier would come to this conclusion if the test utterance did not fall
within any of the gaussian mixtures of any of the hmms (which were trained on
all of the training data).

- Can you think of some alternative methods for doing speaker identification
that donâ€™t use Gaussian mixtures?

The MFCC represents each piece of speech as a 14 dimensional vector, so it is
possible that a simple k-nearest-neighbours approach could accurately group
together similar utterances based on the total Euclidean distance between the
values of each of the 14 dimensions for any two compared utterances.

3.3 Levenshtein distance
------------------------

In this section we measured the Levenshtein distance between the transcriptions
from hypothesis.txt, and the reference sentences unkn_1.txt - unkn_30.txt, from
the speechdata/Testing directory. Th values for the entire data set were SE =
0.134375, IE = 0.034375, DE = 0.040625, and LEV_DIST = 0.209375.

4.1 Report
----------

Using the IBM Watson speech recognition platform, the .flac files from
speechdata/Testing were transcribed and the Levenshtein algorithm was run on
them to calculate the Levenshtein distance of the results. The IBM assisted
transcription was listed in ibm_hypotheses.txt.

4.2
---



Bonus
-----

Voice banking bonus completed; usernames for the voicebanking portion are in
ID.txt.
